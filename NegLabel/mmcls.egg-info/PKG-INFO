Metadata-Version: 2.2
Name: mmcls
Version: 0.23.1
Summary: OpenMMLab Image Classification Toolbox and Benchmark
Home-page: https://github.com/open-mmlab/mmclassification
Author: MMClassification Contributors
Author-email: openmmlab@gmail.com
License: Apache License 2.0
Keywords: computer vision,image classification
Classifier: Development Status :: 4 - Beta
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: matplotlib
Requires-Dist: numpy
Requires-Dist: packaging
Provides-Extra: all
Requires-Dist: albumentations>=0.3.2; extra == "all"
Requires-Dist: colorama; extra == "all"
Requires-Dist: requests; extra == "all"
Requires-Dist: rich; extra == "all"
Requires-Dist: matplotlib; extra == "all"
Requires-Dist: numpy; extra == "all"
Requires-Dist: packaging; extra == "all"
Requires-Dist: codecov; extra == "all"
Requires-Dist: flake8; extra == "all"
Requires-Dist: interrogate; extra == "all"
Requires-Dist: isort==4.3.21; extra == "all"
Requires-Dist: mmdet; extra == "all"
Requires-Dist: pytest; extra == "all"
Requires-Dist: xdoctest>=0.10.0; extra == "all"
Requires-Dist: yapf; extra == "all"
Provides-Extra: tests
Requires-Dist: codecov; extra == "tests"
Requires-Dist: flake8; extra == "tests"
Requires-Dist: interrogate; extra == "tests"
Requires-Dist: isort==4.3.21; extra == "tests"
Requires-Dist: mmdet; extra == "tests"
Requires-Dist: pytest; extra == "tests"
Requires-Dist: xdoctest>=0.10.0; extra == "tests"
Requires-Dist: yapf; extra == "tests"
Provides-Extra: optional
Requires-Dist: albumentations>=0.3.2; extra == "optional"
Requires-Dist: colorama; extra == "optional"
Requires-Dist: requests; extra == "optional"
Requires-Dist: rich; extra == "optional"
Provides-Extra: mim
Requires-Dist: mmcv-full<1.6.0,>=1.4.2; extra == "mim"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: summary

# Negative Label Guided OOD Detection with Pretrained Vision-Language Models


Official PyTorch implementation of the ICLR 2024 (Spotlight) paper:

**[Negative Label Guided OOD Detection with Pretrained Vision-Language Models](https://openreview.net/forum?id=xUO1HXz4an)**

Xue Jiang, Feng Liu, Zhen Fang, Hong Chen, Tongliang Liu, Feng Zheng, Bo Han

<p align="center">
  <img src="https://github.com/XueJiang16/NegLabel/blob/main/neg_label_fig1.png?raw=true" width=100%/>
</p>  

Abstract: *In this paper, we propose a novel post hoc OOD detection method, called NegLabel, which takes a vast number of negative labels from extensive corpus databases. We design a novel scheme for the OOD score collaborated with negative labels. Theoretical analysis helps to understand the mechanism of negative labels. Extensive experiments demonstrate that our method NegLabel achieves state-of-the-art performance on various OOD detection benchmarks and generalizes well on multiple VLM architectures. Furthermore, our method NegLabel exhibits remarkable robustness against diverse domain shifts.*



## Installation

The project is based on MMClassification. MMClassification is an open source image classification toolbox based on PyTorch. It is a part of the [OpenMMLab](https://openmmlab.com/) project.

Below are quick steps for installation:

```shell
conda create -n open-mmlab python=3.8 pytorch==1.10 torchvision==0.11.2 cudatoolkit=11.3 -c pytorch -y
conda activate open-mmlab
pip install openmim
cd NegLabel
mim install -e .
pip install ftfy regex tqdm
pip install git+https://github.com/openai/CLIP.git
```

## Dataset Preparation

#### In-distribution dataset

Please download [ImageNet-1k](http://www.image-net.org/challenges/LSVRC/2012/index) and place the training data (not necessary) and validation data in
`./data/id_data/imagenet_train` and  `./data/id_data/imagenet_val`, respectively.

#### Out-of-distribution dataset

Following [MOS](https://arxiv.org/pdf/2105.01879.pdf), we use the following 4 OOD datasets for evaluation: [iNaturalist](https://arxiv.org/pdf/1707.06642.pdf), [SUN](https://vision.princeton.edu/projects/2010/SUN/paper.pdf), [Places](http://places2.csail.mit.edu/PAMI_places.pdf), and [Textures](https://arxiv.org/pdf/1311.3618.pdf).

Please refer to [MOS](https://github.com/deeplearning-wisc/large_scale_ood), download OOD datasets and put them into `./data/ood_data/`.

## About Negative Labels

We provide the wordnet database in `./txtfiles`. We dynamically calculate and select negative labels based on the given ID labels and the database before the inference stage. We do not directly provide txt files for the selected negative labels. For details, please refer to  `./mmcls/models/classifiers/multi_modal.py/#L140`. 

## OOD Detection Evaluation

To reproduce our results, please run:

```bash
bash ./run.sh
```



## Citation


```
@inproceedings{
jiang2024negative,
title={Negative Label Guided {OOD} Detection with Pretrained Vision-Language Models},
author={Xue Jiang and Feng Liu and Zhen Fang and Hong Chen and Tongliang Liu and Feng Zheng and Bo Han},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=xUO1HXz4an}
}
```
